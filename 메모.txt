zero -> backward -> update
(optimizer.zero_grad, loss.backward, optimizer.step)

<Trainer>
학습 시킬떄 필요한 것:
학습 시킬 모델, 학습 하는데 사용될 optim 방식, loss 계산을 해야 모델 학습이 이루어짐으로 loss_fn, 학습하는데 사용될 데이터셋,
디바이스는 사실 세부적인 학습 조건에 선언하는게 의미적으로는 더 맞지만 추후 학습 진행할때 dataloader 에서 뽑아온 x, y 를 device 로 옮겨야 하기 떄문에 여기서 그냥 설정
model, optimizer, loss_fn, train_dataloader, device

세부적인 학습 조건 (running 에서 셋팅)
몇 에폭 학습 할지, 기존의 체크포인트 파일 존재하는지
num_epoch, checkpoint_file, 추가적으로 test 해보기 위한 여러가지 인자들


<Tester>
테스트 할 떄 필요한것:
위에서 추가적으로 테스트 하기 위해서는 정량적인 평가지표가 필요하므로 metric_fn.
혹시 loss 의 변화를 굳이 확인하고 싶다면 loss_fn 도 추가 가능
model, test_dataloader, metric_fn, device

<.to>
Module 에는 in-place 로 작동
일반적인 tensor 에는 in-place 로 작동 안함
net.to('cuda')
x = x.to('cuda')
이렇게 사용해야 정상 작동

<model.train()>
model.train()을 다른 곳에서 model.eval()로 변경되었다면 다시 model.trian()으로 설정해줘야 함.
Trainer 에서 테스트 하는 과정에서 eval()로 바뀌기 때문에 나는 학습 될때마다 train()으로 설정을
확실시하기위해 _trian() 코드 안에 .train() 설정 해주었음

<trouble shooting>
- RuntimeError: Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor)
should be the same or input should be a MKLDNN tensor and weight is a dense tensor
자료형이 서로 다르다는 건데 input 은 일반 Tensor, weight(모델) 은 cuda Tensor.
즉, 모델 뿐만 아니라 input (x, y) 도 cuda 로 옮겨줘야 함 (.to('cuda'))

- RuntimeError: Expected all tensors to be on the same device,
but found at least two devices, cuda:0 and cpu!
(when checking arugment for argument target in method wrapper_nll_loss_forward)
모든 Tensor (Module 말고) 들이 같은 위치에 있어야 한다 함은 현재 input 으로 들어간 x, y 가 서로 다른
device 에 잡혀있다는 의미. 즉 x 만 .to('cuda') 이렇게 해주면 이런 오류 남. 먼저 모델에 x 넣어서 나온 결과와(cuda)
실제 y 값(cpu) 비교하는 과정에서 발생하는 에러.
따라서 x, y 둘 다 cuda 로 옮겨줄것.

불러오기 후 학습 진행시 optimizer 선언 전에 model 위치 안맞춰주면 오류남
불러오기 안할때는 그냥 optimizer 선언한 뒤에 model 위치 바꿔줘도 오류 안남
아마 학습이 시작된 뒤부터는 optimizer 가 model 정보를 갖고 있는듯
그래서 불러오기 안하고 학습 할때는 optimizer 선언 뒤에 model 위치 바꿔도 이제 학습 시작하면서
parameter 들이 변경 되는데
불러오기 하고 나서는 이미 optimizer 가 기대하고 있는 model 의 위치가 있어서 optimizer 불러오기 전에
model 위치를 잡아줘야 하는듯

검색 결과
SGD, Adam optimizer 는 step 단계에서 모델 정보를 담기 때문에 불러오기 말고 처음 학습 수행 할떄는 step 전까지는
모델을 다른 위치로 옮겨도 무방.
하지만 다른 optimizer 들은 init 단계에서 모델 정보를 담기 때문에 optimizer 선언 전에 모델 위치를 미리 옮겨놔야 함
Adagrad 로 하는 경우 불러오기 안해도 모델 옮기면 오류 나는거 확인할 수 있음
Q. gpu로 셋팅 다해서 학습 돌리다가 중간에 모델 cpu로 바꾸면? -> 왠지 모델 학습이 않될것 같음. loss 변화 없이 진행.
다른 녀석을 optimizer 가 학습하고 있으니까
해보니 일단 그냥 device 2개라고 실행 자체가 안됨.

결론적으로 device 는 미리 설정해놓기


<numpy, detach>
1. TypeError: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.
tensor -> numpy 로 바꾸려면 먼저 cuda 에 있는걸 cpu 로 옮겨야 함
2. RuntimeError: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.
grad_fn 있는 tensor 의 경우에는 detach 해줘야 함. grad_fn 없는 tensor는 detach 없이 바로 진행

<tolist()>
np.argmax(a=y_pred.tolist(), axis=1) 에서 y_pred 를 굳이 .cpu().detach().numpy() 할 것 없이 바로 list 로 바꿔주어도 됨
